# ===========================================
# LLM FALLBACK PARSER CONFIGURATION
# ===========================================

# OpenAI API key for LLM parsing
OPENAI_API_KEY=your_openai_api_key_here

# Parser Operation Mode
USE_LLM_PARSER=true     # Set to 'true' to always use LLM, 'false' for NER+regex with LLM fallback

# LLM Model Configuration
LLM_MODEL=gpt-3.5-turbo   # The OpenAI model to use
LLM_TEMPERATURE=0.2       # Controls randomness (0-1)
LLM_MAX_TOKENS=1000       # Maximum response length
LLM_CONFIDENCE=0.85       # Confidence assigned to LLM results

# ===========================================
# CONFIDENCE THRESHOLDS
# ===========================================

# Confidence threshold for parser fallback (default: 0.6)
# Only used when USE_LLM_PARSER=false
CONFIDENCE_THRESHOLD=0.6

# ===========================================
# STATISTICS AND LOGGING
# ===========================================

# Whether to save parser usage statistics
SAVE_STATS=true

# Path to save stats file
STATS_FILE=parser_stats.json

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# ===========================================
# TESTING INSTRUCTIONS
# ===========================================
# To test the LLM fallback:
# 1. Rename this file to .env 
# 2. Replace 'your_openai_api_key_here' with your actual OpenAI API key
# 3. Set USE_LLM_PARSER=true to always use the LLM parser
# 4. Run python check_env.py to validate your settings
# 5. Run python test_gpt35.py to test the LLM parser with a sample document 